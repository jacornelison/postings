<!DOCTYPE html>

<!--suppress HtmlDeprecatedAttribute -->
<head>
    <meta charset="utf-8">
    <title>IPR: Unblinding Strategy</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <!-- Load up MathJax for math notation -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            TeX: { equationNumbers: { autoNumber: "AMS" } }
        });
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
              tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <script type="text/javascript"
            src="../mathjax/MathJax.js?config=TeX-AMS-MML_SVG">
            // src="../mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

</head>

<body>
<!-- Add my custom pager script -->
<script type="text/javascript" src="scripts/pager.js"></script>
<link rel="stylesheet" type="text/css" href="scripts/pager.css">

<header>
    <h1>Isotropic Polarization Rotation Analysis: Unblinding Strategy</h1>

    <time datetime="2022-12-13" class="published updated">
        2023 MMM DD
    </time> â€”
    J. Cornelison
</header>

<hr>

<p>
    Abstract
</p>

<hr>

<section><h2>Overview</h2>


</section>

<section>
    <h2>Unblinding Strategy</h2>
    <p>
        Our constraint should take the form of a single number with error bars but there are multiple ways to go about getting that number and we've decided on two in order to have some cross checks.
    </p>

    <ul>
        <li><b>Approach 1 (Sernum 6606):</b> Creating sims with the same configuration in which we expect the real BICEP3 data used for BK18 to be. I.E. the TOD's are made with angles I have measured from the RPS, but the maps are made using ideal polarization angles.</li>
        <li><b>Approach 2 (Sernum 6621):</b> Creating sim TOD's with the RPS-derived angles and then creating both real and sim maps with the RPS-derived polarization angles.</li>
    </ul>

    <p>
        These two parallel approaches are intended to be cross-checks of one another, but if we've done everything right then either approach should spit out the same number for our birefringence constraint.
</p>
    <p>
        In either case, we expect that the angles going into TOD and Map making ($\alpha_{TOD}$, $\alpha_{MAP}$ resp.) are the same for both the sims and real data. That way, the excess angle resulting from cosmic birefringence, $\beta$ (in keeping with the naming convention in the literature), is just the difference between the angle fit from the real spectra, $\alpha_{real}$, and the mean angle from the sims, $\bar{\alpha}_{sims}$.
    </p>

    \begin{equation}
    \begin{split}
    \alpha_{sims} &= \alpha_{TOD}-\alpha_{MAP}\\
    &\\
    \alpha_{real} &= \alpha_{TOD}-\alpha_{MAP}+\beta\\
    &\\
    \beta &= \alpha_{real}-\bar{\alpha}_{sims}\\
    \end{split}
    \end{equation}

    <p>I plan on presenting constraints with angles fit to Type 8 (L-LCDM+Noise+Dust) EB spectra both using our typical 9 bandpowers along with an additional 5 (bins 11-15) which should also provide another level of consistency. As of this posting, I intend to report all four results (2 approaches, 2 &ell;-ranges) in a table in the paper, but have <b>our official results be from Approach 2 fitting to all 14 bins</b>. To use the higher bins will require a confirmation that the beam uncertainties are sufficiently small, but we're currently working on that (See &sect; 4 for a list of things we still need to complete).
    </p>

    <h3>Unblinding Plots</h3>

    <p>The following plots are what I'll be looking at when we officially unblind -- I'm currently substituting the spectra from realization 1 from the sims in lieu of using the real data. Both of the approaches above will each have a set of their own plots. Right now I'm only showing the plots from Approach 1 as the sims for Approach 2 still need to be completed.</p>

    <p>
        Before we even look at angles, I want to first look at the EB spectra from which they are derived in order to ensure nothing obviously crazy is happening, quantitatively shown by chi-squares and their PTE's. Remember that our limits on PTE's are 0.01 < PTE < 0.99.
    </p>
    <figure>
        <img src="figs\unblinded_spectra_6606_test.png">
        <figcaption>
            EB power spectra for Approach 1. Grey lines are individual sim realizations; black line is the mean of sims; and the red and blue lines will be the real spectra out to bins 10 and 15 respectively -- to remain blinded, these lines are currently just realization 1 from the sims.
        </figcaption>
    </figure>

    <p>
        Next, we'll actually look at the histograms of &beta; for fitting to both bin-ranges.
        The standard deviation of the histograms give us the statistical uncertainty from the sims, but we still need to include the systematic uncertainty from alternate dust models and beam uncertainties.
        However, since we expect these to be subdominant to the statistical uncertainty, this should provide us a solid visual indication of whether or not we have a detection.
    </p>

    <figure>
        <img src="figs\unblinded_hists_6606_test.png">
        <figcaption>
            Histograms of &beta; for Approach 1. The blue bars are the sims and the green line is the real data (rlz 1 of the sims here). The black dotted lines show the 2&sigma; error bars.
        </figcaption>
    </figure>

    <p>Finally, I'll also include a table of &beta; with the final statistical and systematic uncertainties which will include any error we get from the instrumental calibration that aren't already accounted for in the sims.</p>


   <h3>Detection Criteria and Consequences</h3>
    <h4>What constitutes a detection?</h4>
    <p>I'd like to establish a detection threshold of 2.5&sigma;, i.e. our constraint will be consistent with the null hypothesis if it satisfies:</p>

    \begin{equation}
    \label{eq:sigthresh}
    \frac{|\beta|}{\sigma_{\beta}} \le 2.5
    \end{equation}

<p>
    My reasoning is that we expect a total &sigma;<sub>&beta;</sub> of ~0.1&deg; and 3&sigma; puts us really close to being possibly being consistent with the recent <i>Planck</i> results of 0.35 even if we measure an angle of zero. I'd like to have a lower threshold to definitively rule out either zero or the results from <i>Planck</i> if I can.
    I chose 2.5&sigma; specifically and not 2&sigma; because, as we saw above, even some of our sims exceed 2&sigma;.
</p>

    <p>If our value of &beta; satisfies Eq. \ref{eq:sigthresh}, then we will finish the paper establishing some nice bounds on isotropic birefringence.</p>


    <h4>What happens if we've detected something?</h4>
    <p>One could pose the argument that if we are confident enough to publish a &beta;=0 constraint, then we should be confident enough to publish a &beta;&ne;0 constraint.
    My major counterpoint to this argument is that I've been solely responsible for most of the parts of this very complicated analysis and while we have no reason to believe that &beta;=0 would be a result from some systematics I've missed, I think that a significant detection of &beta; should at least warrant getting some other eyes on all of the little details that went into the result.
    </p>
<p>
    That said, I propose that if &beta;&ne;0 to greater than the 2.5&sigma; threshold, then we pause releasing the paper until we can
    <ol type="A">
    <li>Have at least one other person who isn't me, Clara, or John independently go through the entire analysis</li>
    <li>Maybe get another RPS observation as an independent cross check.</li>

</ol>
</p>

    <p>
        I predict that the first question that might be asked is "then why don't we just wait to unblind and do those things first?" and my answer to that is "I need to graduate and it'd be <i>real</i> unsatisfying to get all this way and not have a result in my thesis". Here at Harvard, we can embargo the public release of our thesis for up to one year, so if we have a non-zero result my plan is to finish my thesis including these results and hold the public release so that we have time to complete the steps above.
    </p>

</section>


<section>
    <h2>Consistency Tests</h2>
<p>
    Before we unblind, we'll perform the same consistency tests (i.e. jackknives) on the reprocessed real data as we do for our standard <i><b>r</b></i> analysis as well as an additional consistency test which will help boost our confidence in the RPS-derived angles. All of these jacks will need to pass in order to go ahead with unblinding.
</p>
<p>
    So far, I've been skipping the creation of the standard jacks when making sims to save time, but now I'm going back an rerunning them. Information on the extra consistency test, which I call a &Delta;&alpha; test, can be found in <a href="JAC2023g"></a>.
</p>

</section>

<section>
    <h2>Questions that still need answers</h2>
<p>
    In addition to the consistency tests discussed above, there are also a few more threads that need to be closed before we can unblind and be fully confident in the 2.5&sigma; detection threshold we established above.
</p>

    <p>
        A link is provided if a draft posting exists for it already.
    </p>

    <ul>
        <li>What is the predicted impact on the birefringence angle bias/uncertainty from non-gaussian dust models?</li>
        <li>What evidence do we have that the RPS-derived angles are accurate?</li>
        <li>What is the predicted impact on the birefringence angle bias/uncertainty from beam systematics?</li>
        <li>What can we say about our uncertainty on the orientation of the focal plane at any given time? What cross checks do we have that can lend confidence that we understand how the pointing model is impacting our instrumental calibration uncertainty?
        </li>
        <li>
            What cross checks do we have on the calibration of the wire grid to gravity?
        </li>
        <li>
            What is the total uncertainty contribution to the birefringence angle from the instrumental calibration and how does it interface with the uncertainty derived from the CMB analysis?
        </li>
        <li>
            How certain are we that we've got the sign of &beta; correct?
        </li>


    </ul>

    <p>
        Which seems like a lot but, as you can see, most of these threads have postings associated with them and are close to being closed.
    </p>

</section>


<section><h2>Conclusions</h2>

</section>

<hr>

<section class="appendix">
<h2 class="appendix">Appendix</h2>
    <h3>Footnotes</h3>
    <p>Click on the number to return to the main text.</p>
    <div class="footnote">
        <p>
        <sup><a name="ftn1" href="#sup1">[1]</a></sup>
    </p>
    </div>

    <!--
    <h3>Code</h3>
    <p>Below is a list of code that was used for this analysis. The code is committed to the pipeline and can be found in the <tt>analysis/beammap/</tt> directory.</p>
    <p id="code"></p>

    <p id="testp"></p>

    <script type="text/javascript">

        // Shorthand tags
        var codes = [
            "rps_fit_mirror_from_moon.m",
            ];

        // Posting titles
        var desc = [
            "Derives mirror parameters from observations of the moon.",
        ];

        // Make a list of references
        var post = document.getElementById("code");
        var msg = "<table class=\"code\">";
        for (var code in codes){
            msg = msg + "<tr><td><tt>"+codes[code]+"</tt></td><td> - </td><td>"+desc[code]+"</td>";
        };
        msg = msg+ "</table>";
        post.innerHTML = msg;

    </script>


    <h3>Data</h3>
    <p id="data"></p>



    <script type="text/javascript">

        // Shorthand tags
        var data = [
            "moonsch.mat",
            ];

        // Posting titles
        var desc = [
            "Metadata of Moon observations",
            ];

        // Make a list of references
        var post = document.getElementById("data");
        var msg = "<table class=\"code\">";
        for (var datum in data) {
            msg = msg + "<tr><td><tt>" + data[datum] + "</tt></td><td> - </td><td>" + desc[datum] + "</td>";
        }
        ;
        msg = msg + "</table>";
        post.innerHTML = msg;

    </script>
-->


    <h3>References</h3>

    <p id="references"></p>


    <script type="text/javascript">

        // This my way of making shorthand links.
        // We'll make a couple arrays with the 'tag' and href information
        // and then look through each anchor element for the specified tag.
        // The anchors should then just look like: <a href="tagname"></a>
        // and the script will automatically fill in the hyperlings and text.


        var posting_dir = window.location.href; // What's the current url?

        var bkurl = "bicep.rc.fas.harvard.edu";
        var spurl = "bicep.usap.gov";

        // These are the possible places to find postings
        // The strings are for if you post your posting in that directory.
        var sitemap = {
            jcornelison: "../../../",   // /jcornelison/postings/
            bkcmb : "../../../../",     // /bkcmb/analysis_logbook/analysis/
            bicep3: "../../../",        //
            bicep_array: "../../../",   //
            bicep2: "",                 // We shouldn't be posting in these, but still have postings we can reference.
            keck  : "",                 // keck/analysis_logbook/analysis/
            spuder: "",                 // ~spuder/hieno_analysis_logboo
            bicep1: "",                 // ~bicep1/analysis_logbook_north/
            general_projects:"",
                   };
        // Logbook Site map:
        // personal:www/jcornelison/postings/
        // bkcmb:   www/bkcmb/analysis_logbook/analysis/
        // keck:    www/keck/analysis_logbook/analysis/
        // BICEP3:  www/bicep3/analysis_logbook/
        // BA:      www/bicep_array/analysis_logbook/
        // We shouldn't be posting in these, but still have postings.
        // bicep2:
        // keck:    www/keck/analysis_logbook/analysis/
        // spuder:  www/~spuder/hieno_analysis_logbook/
        // bicep1:  www/~bicep1/analysis_logbook_north/

        // Shorthand tags
        var tags = [
            "JAC2023a",
            "JAC2023b",
            "JAC2023c",
            "JAC2023d",
            "JAC2023e",
            "JAC2023f",
            "CV2023",
            "JAC2023g"
        ];

        // Links
        // Truncate the link down to the www directory in which it lies if you can.
        // This ensures that we can view the linked postings at Pole without the internet.
        var hrefs = [
            "bkcmb/analysis_logbook/analysis/20230207_IPR_angle_fits_to_B2018/",
            "bkcmb/analysis_logbook/analysis/20230214_IPR_B18_mat_pure/",
            "bkcmb/analysis_logbook/analysis/20230214_IPR_pol_rot_sims/",
            "jcornelison/postings/20230321_IPR_high_ell/",
            "jcornelison/postings/20230321_IPR_forecasting/",
            "jcornelison/postings/20230321_IPR_B18_subsets/",
            "cverges/20221215_alt_dust_sim/",
            "jcornelison/postings/2023mmdd_IPR_det_subset_jacks/",
        ];


        // Posting titles
        var desc = [
            "Isotropic Polarization Rotation Analysis: Global Polarization Rotation Fits on Standard B2018 Sims",
            "Isotropic Polarization Rotation Analysis 2: B18 sims and combined EB+TB fits",
            "Isotropic Polarization Rotation Analysis 3: B2018 Polarization Rotation sims",
            "Isotropic Polarization Rotation Analysis 4: Angle estimates including higher ell-bins",
            "Isotropic Polarization Rotation Analysis 5: Basic Forecasting of Angle Uncertainty on B18 sims",
            "Isotropic Polarization Rotation Analysis 6: Angle Fits With Reduced Coverage in B18 sims",
            "Isotropic Polarisation Rotation Analysis 7: Alternate dust models",
            "Isotropic Polarization Rotation Analysis 8: An RPS Angle Subset Jack",
        ];
        // Debug
        var posty = document.getElementById("testp");


        var preface = "";
        var keys = Object.keys(sitemap);
        // If we're not at pole or bicep, just post the full URL
        // If we are, go back to the www directory.
        if (posting_dir.match(new RegExp(bkurl))!=bkurl &
            posting_dir.match(new RegExp(spurl))!=spurl){
                preface = "http://" + bkurl+"/";
            }
        else {
            for (key in keys){
                if (posting_dir.match(new RegExp("/"+keys[key]+"/"))=="/"+keys[key]+"/"){
                    preface = sitemap[keys[key]];
                };
            };

        };

        // Add the prefixes we can.
        // Only add prefixes to directories in the sitemap so we don't break
        // external references.
        for (ref in hrefs) {
            for (key in keys) {

            // If there's a match, at the prefix and move on.
            if(hrefs[ref].match(new RegExp(keys[key] + "/"))==keys[key]+"/"){
                hrefs[ref] = preface+hrefs[ref];
                break;
            }
            };
        };

        // posty.innerHTML = preface;

        // Make a list of references
        var post = document.getElementById("references");
        var msg = "<table>";
        for (var tag in tags){
            msg = msg + "<tr><td><a href="+tags[tag]+"></a></td><td> - </td><td>"+desc[tag]+"</td>";
        };
        msg = msg+ "</table>";
        post.innerHTML = msg;

        // Look through all the hyperlinks and insert the proper links to the postings
        var links = document.getElementsByTagName("A");
        for (var link in links){
            for (var tag in tags){
                if (links[link].href.endsWith(tags[tag])){
                    links[link].text = "("+tags[tag]+")";
                    links[link].href = hrefs[tag];
                    links[link].target = "_blank";
                }
            }
        }

    </script>
</section>
</body>
